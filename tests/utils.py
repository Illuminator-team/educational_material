from pathlib import Path
import pytest
import subprocess
import nbformat
from nbclient import NotebookClient
import pandas as pd
import numpy as np


def execute_scenario(scenario_path : Path):
    """
    Executes an Illuminator scenario YAML file.

    This function runs the command-line `illuminator scenario run <file>` 
    using the scenario YAML file provided. It asserts that the command 
    completes successfully.

    Parameters:
    ----------
    scenario_path : Path
        Path to the Illuminator scenario YAML file.

    Raises:
    ------
    AssertionError
        If the scenario execution fails (non-zero return code).
    """
    # Run scenario
    result = subprocess.run(
        ["illuminator", "scenario", "run", str(scenario_path.name)],
        cwd=scenario_path.parent,
        capture_output=True,
        text=True
    )

    # Check execution was successful
    assert result.returncode == 0, (
        f"Execution failed for {scenario_path}.\n"
        f"STDOUT:\n{result.stdout}\n\nSTDERR:\n{result.stderr}"
    )


def execute_notebook(notebook_path : Path):
    """
    Executes a Jupyter notebook in-place.

    This function reads the given notebook, executes it using `nbclient`,
    and raises a test failure via pytest if any cell errors occur during execution.

    Parameters:
    ----------
    notebook_path : Path
        The path to the notebook file to be executed.

    Raises:
    ------
    pytest.fail
        If execution of the notebook raises any error.
    """
    nb = nbformat.read(notebook_path, as_version=4)
    client = NotebookClient(nb, timeout=300, resources={"metadata": {"path": str(notebook_path.parent)}})

    try:
        client.execute()
    except Exception as e:
        pytest.fail(f"Execution failed for {notebook_path}:\n{e}")


def compare_output_files(
        actual: Path,
        expected: Path,
        date_columns: list[str] = [],
        text_columns: list[str] = [],
        float_columns: list[str] = [],
        tolerance: float = 1e-6
):
    """
    Compare two CSV files produced by an Illuminator example for equality.

    This function verifies that:
    - The actual output file exists.
    - The shape of the actual and expected DataFrames match.
    - The "date" columns are identical.
    - Specified float columns match within a numerical tolerance.
    - Specified text columns match exactly.

    Parameters
    ----------
    actual : Path
        Path to the output CSV file generated by the example.

    expected : Path
        Path to the reference CSV file with expected results.

    date_columnns : list[str]
        List of column names containing dates to compare exactly

    float_columns : list[str]
        List of column names containing floating-point values to compare with tolerance.

    text_columns : list[str], optional
        List of column names containing text values to compare exactly (default is empty).

    tolerance : float, optional
        Absolute tolerance for floating-point comparison (default is 1e-6).

    Raises
    ------
    AssertionError
        If the file is missing, or if any comparison fails.
    """
    # Check the output file was generated by the notebook
    assert actual.exists(), f"Missing output file: {actual.name}"

    # Load files into data frames
    parse_dates = date_columns if date_columns else None
    df_expected = pd.read_csv(expected, parse_dates=parse_dates)
    df_actual = pd.read_csv(actual, parse_dates=parse_dates)

    # Compate file rows and columns
    assert df_actual.shape == df_expected.shape, f"{actual.name}: Output files have different shapes"

    # Compare date columns exactly
    for col in date_columns:
        assert col in df_actual.columns, f"{actual.name}: Missing column '{col}'"
        assert (df_actual[col] == df_expected[col]).all(), f"{actual.name}: Date columns do not match"

    # Compare text columns exactly
    for col in text_columns:
        assert col in df_actual.columns, f"{actual.name}: Missing column '{col}'"
        assert (df_actual[col] == df_expected[col]).all(), f"{actual.name}: Text values in '{col}' do not match"

    # Compare the float columns with tolerance
    for col in float_columns:
        assert col in df_actual.columns, f"{actual.name}: Missing column '{col}'"
        assert np.allclose(
            df_actual[col],
            df_expected[col],
            rtol=0,
            atol=tolerance
        ), f"{actual.name}: Float values in '{col}' differ beyond tolerance"